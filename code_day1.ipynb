{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehi1150I7fxN"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "link_hilstrom = 'https://drive.google.com/open?id=15osyN4c5z1pSo1JkxwL_N8bZTksRvQuU'\n",
    "fluff, id = link.split('=')\n",
    "downloaded = drive.CreateFile({'id':id})\n",
    "downloaded.GetContentFile('Hillstrom.csv')\n",
    "hillstrom_df = pd.read_csv('Hillstrom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7tAS92JMPe9U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "link_ = 'https://drive.google.com/open?id=1b8N7WtwIe2WmQJD1KL5UAy70K13MxwKj'\n",
    "fluff, id = link.split('=')\n",
    "downloaded = drive.CreateFile({'id':id})\n",
    "downloaded.GetContentFile('Lalonde.csv')\n",
    "lalonde_df = pd.read_csv('Lalonde.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "ZoNrZI5P80wJ",
    "outputId": "88345ba3-d1bc-47e4-c3d7-0686b1bed600"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3ccfb616c717>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    elif dataset in ['criteo', 'ad']:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "def preprocess_data(df, dataset='hillstrom', verbose=True):\n",
    "    # For Hillstrom dataset, the ‘‘visit’’ target variable was selected\n",
    "    #   as the target variable of interest and the selected treatment is \n",
    "    #   the e-mail campaign for women’s merchandise [1]\n",
    "    # [1] Kane K, Lo VSY, Zheng J. True-lift modeling: Comparison of methods. \n",
    "    #    J Market Anal. 2014;2:218–238\n",
    "    dataset = dataset.lower()\n",
    "    if dataset in ('hillstrom', 'email'):\n",
    "        columns = df.columns\n",
    "        for col in columns:\n",
    "            if df[col].dtype != object:\n",
    "                continue\n",
    "            df = pd.concat(\n",
    "                    [df, pd.get_dummies(df[col], \n",
    "                                        prefix=col, \n",
    "                                        drop_first=False)],\n",
    "                    axis=1)\n",
    "            df.drop([col], axis=1, inplace=True)\n",
    "\n",
    "        df.columns = [col.replace('-', '').replace(' ', '_').lower()\n",
    "                      for col in df.columns]\n",
    "        df = df[df.segment_mens_email == 0]\n",
    "        df.index = range(len(df))\n",
    "        df.drop(['segment_mens_email', \n",
    "                 'segment_no_email', \n",
    "                 'conversion', \n",
    "                 'spend'], axis=1, inplace=True)\n",
    "\n",
    "        y_name = 'visit'\n",
    "        t_name = 'segment_womens_email'\n",
    "    elif dataset in ['criteo', 'ad']:\n",
    "        raise NotImplementedError\n",
    "    elif dataset in ['lalonde', 'job']:\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    df['Y'] = df[y_name]\n",
    "    df.drop([y_name], axis=1, inplace=True)\n",
    "    df['T'] = df[t_name]\n",
    "    df.drop([t_name], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Igf3QLgdJ1cW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def performance(pr_y1_ct1, pr_y1_ct0, y, ct, groups=10):\n",
    "    \"\"\"\n",
    "    1. Split the total customers into the given number of groups\n",
    "    2. Calculate the statistics of each segment\n",
    "    \n",
    "    Args:\n",
    "        pr_y1_ct1: the series (list) of the customer's expected return\n",
    "        pr_y1_ct0: the expected return when a customer is not treated\n",
    "        y: the observed return of customers\n",
    "        ct: whther each customer is treated or not\n",
    "        groups: the number of groups (segments). Should be 5, 10, or 20\n",
    "    Return:\n",
    "        DataFrame:\n",
    "            columns:\n",
    "                'n_y1_ct1': the number of treated responders\n",
    "                'n_y1_ct0': the number of not treated responders\n",
    "                'r_y1_ct1': the average return of treated customers\n",
    "                'r_y1_ct0': the average return of not treated customers\n",
    "                'n_ct1': the number of treated customers\n",
    "                'n_ct0': the number of not treated customers\n",
    "                'uplift': the average uplift (the average treatment effect)\n",
    "            rows: the index of groups\n",
    "    \"\"\"\n",
    "  \n",
    "    ### check valid arguments\n",
    "    if groups not in [5, 10, 20]:\n",
    "        raise Exception(\"uplift: groups must be either 5, 10 or 20\")\n",
    "  \n",
    "    ### check for NAs.\n",
    "    if pr_y1_ct1.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in pr_y1_ct1\")\n",
    "    if pr_y1_ct0.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in pr_y1_ct0\")\n",
    "    if y.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in y\")\n",
    "    if ct.isnull().values.any():\n",
    "        raise Exception(\"uplift: NA not permitted in ct\")\n",
    "   \n",
    "    ### check valid values for ct\n",
    "    if set(ct) != {0, 1}:\n",
    "        raise Exception(\"uplift: ct must be either 0 or 1\")\n",
    "\n",
    "    ### check length of arguments\n",
    "    if not (len(pr_y1_ct1) == len(pr_y1_ct0) == len(y) == len(ct)):\n",
    "        raise Exception(\"uplift: arguments pr_y1_ct1, pr_y1_ct0, y and ct must all have the same length\")\n",
    "\n",
    "    ###############################\n",
    "    ###     Do it yourself!     ###\n",
    "    ###############################\n",
    "    return ##\n",
    "\n",
    "\n",
    "def qini(perf, plotit=True):\n",
    "    \"\"\"\n",
    "    Calculating the incremental gains (y-axis of Qini curve)\n",
    "     - First, the cumulitative sum of the treated and the control groups are\n",
    "      calculated with respect to the total population in each group at the\n",
    "      specified decile\n",
    "     - Afterwards we calculate the percentage of the total amount of people\n",
    "      (both treatment and control) are present in each decile\n",
    "    Args:\n",
    "        perf: A return of the performance function (above)\n",
    "        plotit: whether draw a plot or not\n",
    "    Return:\n",
    "        1. Qini value\n",
    "        2. return or save the plot if plotit is True\n",
    "    \"\"\"\n",
    "    \n",
    "    ###############################\n",
    "    ###     Do it yourself!     ###\n",
    "    ###############################\n",
    "    return ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrxjl1v7J9Mm"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def parameter_tuning(fit_mdl, pred_mdl, data, search_space):\n",
    "    \"\"\"\n",
    "    Given a model, search all combination of parameter sets and find\n",
    "    the best parameter set\n",
    "    \n",
    "    Args:\n",
    "        fit_mdl: model function\n",
    "        pred_mdl: predict function of fit_mdl\n",
    "        data:\n",
    "            {\n",
    "                \"x_train\": predictor variables of training dataset,\n",
    "                \"y_train\": target variables of training dataset,\n",
    "                \"ct_train\": treatment variables of training dataset,\n",
    "                \"x_test\": predictor variables of test (usually, validation) dataset,\n",
    "                \"y_test\": target variables of test (usually, validation) dataset,\n",
    "                \"ct_test\": treatment variables of test (usually, validation) dataset,\n",
    "            }\n",
    "        search_space:\n",
    "            {\n",
    "                parameter_name: [search values]\n",
    "            }\n",
    "    Return:\n",
    "        The best parameter set\n",
    "    \"\"\"\n",
    "    \n",
    "    ###############################\n",
    "    ###     Do it yourself!     ###\n",
    "    ###############################\n",
    "    return ##\n",
    "\n",
    "  \n",
    "def wrapper(fit_mdl, pred_mdl, data)\n",
    "    \"\"\"\n",
    "    General wrapper approach\n",
    "    \n",
    "    Args:\n",
    "        fit_mdl: model function\n",
    "        pred_mdl: predict function of fit_mdl\n",
    "        data:\n",
    "            {\n",
    "                \"x_train\": predictor variables of training dataset,\n",
    "                \"y_train\": target variables of training dataset,\n",
    "                \"ct_train\": treatment variables of training dataset,\n",
    "                \"x_test\": predictor variables of test (usually, validation) dataset,\n",
    "                \"y_test\": target variables of test (usually, validation) dataset,\n",
    "                \"ct_test\": treatment variables of test (usually, validation) dataset,\n",
    "            }\n",
    "    Return:\n",
    "        (A list of best models, The list of dropped variables)\n",
    "    \"\"\"\n",
    "    \n",
    "    ###############################\n",
    "    ###     Do it yourself!     ###\n",
    "    ###############################\n",
    "    return ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxrEbEODlbQi"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def tma(x, y, ct, method=LogisticRegression, **kwargs):\n",
    "    \"\"\"Training a model according to the \"Two Model Approach\" \n",
    "    (a.k.a. \"Separate Model Approach\")\n",
    "    The default model is General Linear Model (GLM)\n",
    "    \n",
    "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
    "\n",
    "    Args:\n",
    "        x: A data frame of predictors.\n",
    "        y: A binary response (numeric) vector.\n",
    "        ct: A binary response (numeric) representing the treatment assignment\n",
    "            (coded as 0/1).\n",
    "        method: A sklearn model specifying which classification or regression\n",
    "            model to use. This should be a method that can handle a \n",
    "            multinominal class variable.\n",
    "\n",
    "    Return:\n",
    "        Dictionary: A dictionary of two models. One for the treatment group, \n",
    "            one for the control group.\n",
    "\n",
    "            {\n",
    "                'model_treat': a model for the treatment group,\n",
    "                'model_control': a model for the control group\n",
    "            }\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    treat_rows = (ct == 1)\n",
    "    control_rows = (ct == 0)\n",
    "    model_treat = method(**kwargs).fit(x[treat_rows], y[treat_rows])\n",
    "    model_control = method(**kwargs).fit(x[control_rows], y[control_rows])\n",
    "    \n",
    "    res = {\n",
    "        'model_treat': model_treat,\n",
    "        'model_control': model_control,\n",
    "    }\n",
    "    return res\n",
    "\n",
    "\n",
    "def predict_tma(obj, newdata, **kwargs):\n",
    "    \"\"\"Predictions according to the \"Two Model Approach\" \n",
    "    (a.k.a. \"Separate Model Approach\")\n",
    "    \n",
    "    For each instance in newdata two predictions are made:\n",
    "    1) What is the probability of a person responding when treated?\n",
    "    2) What is the probability of a person responding when not treated\n",
    "      (i.e. part of control group)?\n",
    "\n",
    "    Source: \"Incremental Value Modeling\" (Hansotia, 2002)\n",
    "\n",
    "    Args:\n",
    "        obj: A dictionary of two models. \n",
    "            One for the treatment group, one for the control group.\n",
    "        newdata: A data frame containing the values at which predictions\n",
    "            are required.\n",
    "    \n",
    "    Return:\n",
    "        DataFrame: A dataframe with predicted returns for when the customers\n",
    "            are treated and for when they are not treated.\n",
    "    \"\"\"\n",
    "   \n",
    "    if isinstance(obj['model_treat'], LinearRegression):\n",
    "        pred_treat = obj['model_treat'].predict(newdata)\n",
    "    else:\n",
    "        pred_treat = obj['model_treat'].predict_proba(newdata)[:, 1]\n",
    "\n",
    "    if isinstance(obj['model_control'], LinearRegression):\n",
    "        pred_control = obj['model_control'].predict(newdata)\n",
    "    else:\n",
    "        pred_control = obj['model_control'].predict_proba(newdata)[:, 1]\n",
    "    \n",
    "    # pred_treat = obj['model_treat'].predict(newdata)\n",
    "    # pred_control = obj['model_control'].predict(newdata)\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"pr_y1_ct1\": pred_treat,\n",
    "        \"pr_y1_ct0\": pred_control,\n",
    "    })\n",
    "    return pred_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "hREl_CRv9DYC",
    "outputId": "e5847999-b923-4de1-87eb-650813cf65bd"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def ct_y_assign(y, ct):\n",
    "    if y == 1 and ct == 1:\n",
    "        return \"TR\"\n",
    "    elif y == 0 and ct == 1:\n",
    "        return \"TN\"\n",
    "    elif y == 1 and ct == 0:\n",
    "        return \"CR\"\n",
    "    elif y == 0 and ct == 0:\n",
    "        return \"CN\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def y_assign(ct_y):\n",
    "    if ct_y in (\"TR\", \"TN\"):\n",
    "        return 1\n",
    "    elif ct_y in (\"CR\", \"CN\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def ct_assign(ct_y):\n",
    "    if ct_y in (\"TR\", \"CR\"):\n",
    "        return 1\n",
    "    elif ct_y in (\"TN\", \"CN\"):\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    ### Load data ###\n",
    "    df = pd.read_csv('Hillstrom.csv')\n",
    "    dataset = 'hillstrom'\n",
    "    df = preprocess_data(df)\n",
    "    Y = df['Y']\n",
    "    T = df['T']\n",
    "    x = df.drop(['Y', 'T'], axis=1)\n",
    "    ct_y = pd.DataFrame({'Y': Y, 'T': T})\\\n",
    "             .apply(lambda row: ct_y_assign(row['Y'], row['T']), axis=1)\n",
    "    if dataset == 'hillstrom':\n",
    "        fold_gen = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234).split(x, ct_y)\n",
    "    elif dataset == 'lalonde':\n",
    "        fold_gen = KFold(n_splits=5, shuffle=True, random_state=1234).split(x)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#     for model in models:\n",
    "\n",
    "    ### Cross validation ###\n",
    "    for idx, (train_index, test_index) in enumerate(fold_gen):\n",
    "        x_train = x.reindex(train_index)\n",
    "        x_test = x.reindex(test_index)\n",
    "        if dataset == 'hillstrom':\n",
    "            Y = ct_y.apply(y_assign)\n",
    "            T = ct_y.apply(ct_assign)\n",
    "        y_train = Y.reindex(train_index)\n",
    "        y_test = Y.reindex(test_index)\n",
    "        ct_train = T.reindex(train_index)\n",
    "        ct_test = T.reindex(test_index)\n",
    "\n",
    "        mdl = tma(x_train, y_train, ct_train)\n",
    "        pred = predict_tma(mdl, x_test)\n",
    "        print(pred)        \n",
    "        # TODO: performance()\n",
    "        # TODO: qini()\n",
    "\n",
    "        ### Variable selection (General wrapper approach) ###\n",
    "\n",
    "        ### Parameter tuning ###\n",
    "\n",
    "#         print(\"Model: {}\\n\".format(model))\n",
    "#         print(\"Tuning space: \\n\")\n",
    "#         for key, val in search_space.items():\n",
    "#             print(\"    '{}': {}\\n\".format(key, val))\n",
    "#         print(\"Seed: {}\\n\".format(seed))\n",
    "#         print(\"Qini value: mean = {}, std = {}\\n\\n\".format(mean_qini, std_qini))\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9X42GUaj-UX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "skeleton.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
