{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIhpYOtKBfrO"
   },
   "source": [
    "# MLP Pytorch Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRAijQucBkE9"
   },
   "source": [
    "---\n",
    "### Introduction ###\n",
    "In this exercise, you will classify Fisher's `Iris` dataset by using Pytorch. This dataset data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper.\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPopKCa8CUP4"
   },
   "source": [
    "--- \n",
    "### Importing various libraries \n",
    "\n",
    "We import `DataLoader` here. By using the `DataLoader` library, we can easily shuffles our data and loads data in batches according to the `batch_size` you specified.\n",
    "~~~ python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwRRGBjL4dVN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6MKp2KZmK7St"
   },
   "source": [
    "--- \n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OaXzUWPy7SiS"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehi1150I7fxN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "link_iris = 'https://drive.google.com/open?id=1LP7W5xCIFuoi6kUHDNzMUbYr57Efrnf_'\n",
    "fluff, id = link_iris.split('=')\n",
    "downloaded = drive.CreateFile({'id':id})\n",
    "downloaded.GetContentFile('Iris.csv')\n",
    "iris_df = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXPeCwBaCoun"
   },
   "source": [
    "--- \n",
    "### DataLoader\n",
    "1. Split the dataset into training and test dataset\n",
    "\n",
    "2. Make custom `Dataset`\n",
    "\n",
    "3. Define `loader_train` and `loader_test` to load the dataset.\n",
    "~~~ python\n",
    "batch_size = 4\n",
    "loader_train = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6snonzspFCtz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris_df['label'] = iris_df['species'].astype('category').cat.codes\n",
    "iris_df.drop(['species'], axis=1, inplace=True)\n",
    "train_df, test_df = train_test_split(iris_df, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZoNrZI5P80wJ"
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(train_df.drop(['label'], axis=1).values, dtype=torch.float32)\n",
    "Y_train = torch.tensor(train_df['label'].values, dtype=torch.long)\n",
    "X_test = torch.tensor(test_df.drop(['label'], axis=1).values, dtype=torch.float32)\n",
    "Y_test = torch.tensor(test_df['label'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qzmnKNyNLfCT"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        assert(len(x_data) == len(y_data))\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "      \n",
    "train_dataset = CustomDataset(X_train, Y_train)\n",
    "test_dataset = CustomDataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dysuBzXAGuPz"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ivm1YD_QG0On"
   },
   "source": [
    "---\n",
    "### Model\n",
    "\n",
    "We introduce a sample model for you. \n",
    "\n",
    "* Sample Model\n",
    "    * Linear layer (input: 4, output: 5)\n",
    "    * Sigmoid activation function\n",
    "    * Linear layer (input: 5, output: 3)\n",
    "    * Cross Entropy Loss function\n",
    "    \n",
    "The first `Linear layer` has `input: 4` because of 4 input features. The second `Linear layer` has `output: 3` because Fisher's `Iris` dataset has 3 classes.\n",
    "\n",
    "Implement the following pytorch neural network model.\n",
    "\n",
    "~~~ python\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 5)\n",
    "        self.linear2 = torch.nn.Linear(5, 3)\n",
    "        self.activ = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.activ(self.linear(x)))\n",
    "    \n",
    "model = Model()\n",
    "~~~\n",
    "\n",
    "or\n",
    "\n",
    "~~~ python\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 5),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(5, 3)\n",
    ")\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgVKOkkU-TjX"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 5)\n",
    "        self.linear2 = torch.nn.Linear(5, 3)\n",
    "        self.activ = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.activ(self.linear(x)))\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtV_QxpPEgH8"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 5),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(5, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X787bHBLJTIU"
   },
   "source": [
    "---\n",
    "### Cost Function and Optimizer\n",
    "\n",
    "As mentioned, you use `CrossEntropyLoss` for cost function(lossfn), and use `SGD` for optimizer.\n",
    "\n",
    "~~~ python\n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRLEvRXJFkBQ"
   },
   "outputs": [],
   "source": [
    "# Practice Here!\n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XDEBDeT1JZqk"
   },
   "source": [
    "---\n",
    "### Training\n",
    "\n",
    "The training process is as follows:\n",
    "\n",
    "* For each epoch\n",
    "    * For each batch\n",
    "        1. Calculate score from your model\n",
    "        2. Calculate loss with loss function\n",
    "        3. Initialize gradient of optimizer\n",
    "        4. Do backward path with loss\n",
    "        5. Step optimizer and update gradient\n",
    "\n",
    "`cost` is used to store and visualize the losses that calculated in each batch. You iterate `loader_train` and access `coordiates` and `label`. The size of `coordinates` will be `(batch_size, 2)` because of x-coordinate and y-coordinate, and the size of `label` will be `(batch_size)`.\n",
    "~~~ python\n",
    "cost = []\n",
    "def train(model, loader_train, loss_fn, optimizer, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        for coordinates, label in loader_train:\n",
    "            # 1. Calculate score from your model\n",
    "            label_hat = model(coordinates)\n",
    "            # 2. Calculate loss with loss function\n",
    "            loss = lossfn(label_hat, label)\n",
    "            # 3. Initialize gradient of optimizer\n",
    "            optimizer.zero_grad()\n",
    "            # 4. Do backward path with loss\n",
    "            loss.backward()\n",
    "            # 5. Step optimizer and update gradient\n",
    "            optimizer.step()\n",
    "            \n",
    "            cost.append(loss)\n",
    "        if (epoch + 1) % (num_epochs / 10) == 0:\n",
    "            print('Epoch = %d, loss = %.4f' % (epoch + 1, cost[-1]))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_123fkgbFu9a"
   },
   "outputs": [],
   "source": [
    "cost = []\n",
    "def train(model, loader_train, loss_fn, optimizer, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        for coordinates, label in loader_train:\n",
    "            label_hat = model(coordinates)\n",
    "            loss = lossfn(label_hat, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cost.append(loss)\n",
    "        if (epoch + 1) % (num_epochs / 10) == 0:\n",
    "            print('Epoch = %d, loss = %.4f' % (epoch + 1, cost[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZum-ydlJwPH"
   },
   "source": [
    "---\n",
    "### Test your Result ###\n",
    "\n",
    "Check your implementation with this code. You should see the cost(loss) is decreasing and the test result is well classified about `97%` accuracy.\n",
    "~~~ python\n",
    "def check_accuracy(model, loader_test):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    for x, y in loader_test:\n",
    "        scores = model(x)\n",
    "        _, preds = scores.max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "train(model, loader_train, lossfn, optimizer, num_epochs=400)\n",
    "check_accuracy(model, loader_test)\n",
    "plt.plot(cost)\n",
    "plt.show()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "mOQe2uiRGOwF",
    "outputId": "c8ad76ba-d400-49fd-edb1-8235fa03c7b2"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader_test):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    for x, y in loader_test:\n",
    "        scores = model(x)\n",
    "        _, preds = scores.max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "train(model, loader_train, lossfn, optimizer, num_epochs=400)\n",
    "check_accuracy(model, loader_test)\n",
    "plt.plot(cost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9X42GUaj-UX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLP_Pytorch_Tutorial",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
